# Research Tips by Thinking Method

How to effectively collect evidence for each thinking method

---

## ğŸ” Root Cause Analysis

### 5 Why Research Strategy

**Goal**: Find evidence at each level of "Why"

**Research Targets**:
```
Why 1 (Symptom): Internal data (what we observe)
Why 2 (Cause): System logs, metrics
Why 3-4 (Depth): Industry cases, expert resources
Why 5 (Root): Principles, theories, benchmarks
```

**Recommended Sources**:
- **Tier 1**: Our actual data, internal logs
- **Tier 2**: Competitor case analysis, industry reports
- **Tier 3**: Forum discussions, technical blogs

**Example**: Slow API response time
```
Why 1: Database query takes 1800ms
  â†’ Evidence: Our APM tool data

Why 2: Full table scan occurring
  â†’ Evidence: Query execution plan analysis

Why 3: Missing index
  â†’ Evidence: Migration checklist review

Why 4: No performance testing
  â†’ Evidence: Other companies' success cases (Tier 2)

Why 5: Inadequate deployment process
  â†’ Evidence: DevOps best practices documents (Tier 1)
```

---

### Fishbone Research Strategy

**Goal**: Collect evidence across 6 categories

**Research by Category**:

```
1. People
   â””â”€ Research: Team capabilities, education level, industry standards
      Sources: HR data, training reports

2. Process
   â””â”€ Research: Workflows, checklists, best practices
      Sources: Internal documents, industry standards

3. Technology
   â””â”€ Research: Tool selection, configuration, versions
      Sources: Official documentation, technical blogs

4. Materials
   â””â”€ Research: Data quality, libraries, dependencies
      Sources: Our inventory, vendor guides

5. Environment
   â””â”€ Research: System resources, infrastructure, network
      Sources: Monitoring tools, system logs

6. Measurement
   â””â”€ Research: Metrics definition, monitoring, alerts
      Sources: Our dashboards, industry standards
```

**Priority**: Investigate high-impact categories first

---

## ğŸ’¡ Innovation

### SCAMPER Research Strategy

**Goal**: Find examples for each modification approach

**Research by Question**:

```
S (Substitute - Replace):
  Q: How do similar things work differently in other industries?
  Research: Adjacent industry cases, innovation examples

C (Combine - Combine):
  Q: Are there products that combine similar features?
  Research: Integrated product analysis, feature combination cases

A (Adapt - Adapt):
  Q: What has succeeded in different contexts?
  Research: Cross-industry cases, regional examples

M (Modify - Modify):
  Q: What happens when you change attributes?
  Research: Modified product performance, A/B test results

P (Put to another use - Different use):
  Q: Are there examples of using this differently?
  Research: Creative user examples, pivot cases

E (Eliminate - Remove):
  Q: Can it work without core features?
  Research: Minimum viable product (MVP) success cases

R (Reverse - Reverse):
  Q: What happens if you reverse it?
  Research: Reverse-engineering products, market reactions
```

**Recommended Research Sources**:
- **Tier 1**: Official market analysis, academic papers
- **Tier 2**: Successful startup blogs, industry cases
- **Tier 3**: Product Hunt, user reviews

---

### First Principles Research Strategy

**Goal**: Find evidence to validate fundamental assumptions

**Process**:

```
1. Identify core assumptions
   Research: Are our assumptions universal?
   Sources: Industry standards, scientific materials

2. Validate each assumption
   Research: Is this actually true? What are alternatives?
   Sources: Academic papers, experimental data

3. Confirm fundamental principles
   Research: What are the physical/economic laws?
   Sources: Textbooks, scientific papers

4. Reconstruct
   Research: Examples of reconstructing this way
   Sources: Disruptive innovation cases
```

**Example**: "Cars must run on gasoline"

```
Assumption 1: Energy is required â†’ Confirmed (energy physics)
Assumption 2: Only gasoline works â†’ False
  Evidence: Electric vehicles, hydrogen cars in practical use (Tesla, Toyota)

Reconstruction: Diversity of energy storage media â†’ Electric vehicle innovation
```

---

## ğŸ¯ Strategic Planning

### SWOT Research Strategy

**Research Depth by Element**:

```
Strengths:
â”œâ”€ Internal evidence: Financial, technical data
â””â”€ External validation: Customer feedback, competitive analysis

Weaknesses:
â”œâ”€ Internal assessment: Our evaluation
â””â”€ External benchmark: Competitors, industry standards

Opportunities:
â”œâ”€ Market research: Market size, growth rate
â””â”€ Trends: Technology, consumer behavior changes

Threats:
â”œâ”€ Competitor analysis: Competitor strategy, market entry
â””â”€ External factors: Regulation, economic changes
```

**How to Build High-Credibility SWOT**:

1. **Strengths/Weaknesses**: Data-driven (internal metrics)
2. **Opportunities**: Market research (Tier 1-2 reports)
3. **Threats**: Competitor analysis (public information + industry reports)

**What to Avoid**:
- âŒ Subjective opinions only (no evidence)
- âŒ Outdated materials (doesn't reflect trends)
- âŒ Single source only (insufficient verification)

---

### GAP Analysis Research Strategy

**Goal**: Quantify the distance from current â†’ desired state

```
Current State Measurement:
â”œâ”€ Internal data (our metrics)
â””â”€ External benchmark (competitors, industry)

Target State Setting:
â”œâ”€ Market research (achievable level)
â””â”€ Vision (our ambitions)

Gap Analysis:
â”œâ”€ Capability gap: Technology/talent shortage
â”œâ”€ Resource gap: Budget/time shortage
â””â”€ Process gap: Methodology changes needed
```

**Research Priorities**:
1. Accurate measurement of our current state
2. Competitor/industry benchmarks
3. Best-in-class examples

---

## âš™ï¸ Process Improvement

### Pareto Research Strategy

**Goal**: Validate the 80/20 principle with data

**Process**:

```
1. Data collection
   â””â”€ Accurate measurement of current state (internal data)

2. Classification and sorting
   â””â”€ Sort by impact

3. Calculate cumulative percentage
   â””â”€ Identify top 20%

4. Benchmark comparison
   â””â”€ Compare with industry standards (Tier 2 data)

5. Study improvement cases
   â””â”€ Other companies' improvement results (Tier 2-3 cases)
```

**High-Confidence Pareto**:
- âœ… Minimum 1+ month of data
- âœ… Sufficient sample size (minimum 100 incidents)
- âœ… Validation with external benchmarks
- âŒ Subjective categorization
- âŒ Insufficient data

**Example**: Customer satisfaction improvement

```
Complaint frequency by type:
- Slow response: 45% â† Top 20% in Pareto
- Inaccurate information: 28% â† Top 20% in Pareto
- Rude customer support: 12%
- Other: 15%

Top 2 = 73% can be resolved
â†’ Concentrate resources on these two areas

Benchmark: Similar companies reduced churn by 30% through similar improvements
â†’ We can expect similar results
```

---

### PDCA Research Strategy

**Evidence Collection by Stage**:

```
Plan (Plan):
â”œâ”€ Evidence: Historical data, industry cases
â”œâ”€ Hypothesis: Improving this will result in X% improvement
â””â”€ Research: Similar improvement cases

Do (Execute):
â”œâ”€ Measurement: Accurate data collection
â””â”€ Record: Detailed logging

Check (Verify):
â”œâ”€ Comparison: Plan vs actual
â”œâ”€ Root cause analysis: Why the difference?
â””â”€ External verification: Validate our results with benchmarks

Act (Improve):
â”œâ”€ Adjust: Revise the plan
â”œâ”€ Scale: Generalize successful areas
â””â”€ Learn: Reflect for next cycle
```

**High-Confidence PDCA**:
- Minimum 2-3 cycles (confirm it's not short-term luck)
- Comparison with external benchmarks
- Both qualitative and quantitative evidence

---

## âš¡ Decision Making

### OODA Loop Research Strategy

**Fast Decision-Making + Evidence Balance**:

```
Observe (Observe):
â”œâ”€ Real-time data (primary information)
â””â”€ Time constraint: Only essential information

Orient (Orient):
â”œâ”€ Experience-based judgment
â””â”€ Similar past situations (quick retrieval)

Decide (Decide):
â”œâ”€ Decide with 70% information (don't wait for perfection)
â””â”€ Risk calculation: Decision delay vs incomplete decision

Act (Act):
â”œâ”€ Fast execution
â””â”€ Continuous monitoring
```

**Research in OODA**:
- Pre-preparation: Industry standards, experience accumulation
- During observation: Real-time data only (speed priority)
- Result verification: Deep analysis afterward

---

### Kepner-Tregoe Research Strategy

**Goal**: Evidence-based analysis for systematic decision-making

```
Problem Analysis:
â”œâ”€ What is the problem?
â”œâ”€ Where does it occur?
â”œâ”€ When does it occur?
â””â”€ Research: Objective facts (documentation, data)

Cause Analysis:
â”œâ”€ List possible causes
â”œâ”€ Evaluate probability of each cause
â””â”€ Research: Scientific evidence

Decision Analysis:
â”œâ”€ Possible options
â”œâ”€ Pros and cons of each option
â”œâ”€ Risk assessment
â””â”€ Research: Case analysis, benchmarks
```

**High-Confidence Kepner-Tregoe**:
- Tier 1 problem analysis (facts only)
- Tier 2 cause analysis (testing/verification)
- Tier 1-2 decision-making (cases/benchmarks)

---

## ğŸ¤ Integration (Synthesis)

### Dialectic Research Strategy

**Goal**: Validate both opposing perspectives

```
Thesis (Argument):
â””â”€ Research: Evidence for perspective A

Antithesis (Counter-argument):
â””â”€ Research: Evidence for perspective B

Synthesis (Integration):
â””â”€ Research: Cases integrating both perspectives
   (historical cases, organizational change cases, etc.)
```

**Example**: Innovation vs Stability

```
Thesis: "Fast innovation is the key to growth"
  Evidence: Tesla, Amazon, and other rapid innovation companies

Antithesis: "Stability and quality are important"
  Evidence: Toyota quality philosophy, safety-focused airlines

Synthesis: "Balance between innovation and stability"
  Evidence: Amazon - Speed + Stability
           Toyota - Innovation + Quality prioritization
```

---

## ğŸ“Š Information Sources Guide

### Efficient Research Planning

**Research depth by time allocation**:

```
30-minute research:
â”œâ”€ Internal data (required)
â””â”€ 1-2 online resources

2-hour research:
â”œâ”€ Internal analysis
â”œâ”€ 3-5 Tier 2 sources
â””â”€ 1 Tier 1 resource

1-day research:
â”œâ”€ Deep internal analysis
â”œâ”€ 10+ sources (diverse perspectives)
â”œâ”€ Tier 1-2 resources
â””â”€ Expert interviews
```

### Best credibility information by source

**Information available from Tier 1 sources**:
```
Academic papers â†’ Principles, theories, scientific evidence
Government data â†’ Market size, regulations, statistics
Official documentation â†’ Technical specifications, vendor benchmarks
Official announcements â†’ Company performance, strategy
```

**Information available from Tier 2 sources**:
```
Industry reports â†’ Market analysis, trends
Expert blogs â†’ Case studies, practical experience
Trusted media â†’ News, in-depth reports
Conferences â†’ Latest trends, case studies
```

**Information available from Tier 3-4 sources**:
```
User forums â†’ Real user experience, problems
Social media â†’ Real-time reactions, sentiment
Blogs/comments â†’ Diverse perspectives, opinions
```

---

## ğŸ¯ Research Efficiency Tips

### Research Checklist

```
[ ] Is time constraint clear?
[ ] Is the required information specific?
[ ] Are source credibility criteria established?
[ ] Is the internal/external information ratio appropriate?
[ ] Have multiple perspectives been collected?
[ ] Have conflicting information sources been verified?
```

### Tips for quick research

1. **Specific questions**: "Is the market big?" (âœ—) vs "What is our segment's market size?" (âœ“)
2. **Source prioritization**: Find Tier 1 first (high credibility)
3. **Quick verification**: Cross-check with minimum 2 sources
4. **Sufficiency mindset**: Perfection not required, 60%+ confidence enables decision-making

---

**Version**: 1.0.0
**Last Updated**: 2025-11-07
**Purpose**: Practical research methodology by thinking method
