# 기술 선택: 데이터 파이프라인 아키텍처 (Technology Selection: Data Pipeline Architecture)

> **문제 유형**: 기술 의사결정 및 아키텍처 선택
>
> **사용 사고법**: 첫 원칙 분석 (First Principles) → Kepner-Tregoe 의사결정 → GAP 분석
>
> **의사결정 수준**: 기술적 아키텍처 (엔지니어링 팀 수준)

---

## Phase 1: 문제 정의

### 현재 상황

```
데이터 분석 스타트업 (월 100GB 데이터 수집):
- 현재 시스템: Lambda 함수 + RDS (커스텀 파이썬 스크립트)
- 배치 처리: 일 2회 (새벽 2시, 오후 6시)
- 데이터 처리 시간: 2-4시간
- 실시간 분석 필요: 고객이 요청 (현재 불가)
- 팀 규모: Data Engineer 1명, DevOps 부재
- 예상 성장: 월 500GB 목표 (6개월)
```

### 증상 vs 근본 원인

```
증상: "데이터 처리 느리고 실시간 불가"
↓
근본 원인 탐색:
- 배치 처리만 가능?
- 확장성(scalability) 한계?
- 운영(operational) 복잡도 높음?
- 인프라 비용 높음?
- 도구/기술의 부적합?
→ First Principles로 근본 원인 분석
```

### 비즈니스 영향

```
재무적 영향:
- 현재 인프라 비용: $2,000/월
- 성장 시 비용: $8,000+/월 (500GB)
- 운영 비용 증가: Data Engineer 추가 필요 ($80K/년)
- 매출 영향: 실시간 분석 기능 추가 못 함 → 고객 수요 충족 실패

전략적 영향:
- 경쟁사 대비 기술 우위 상실 (경쟁사는 실시간 분석 가능)
- 엔지니어 번아웃 위험 (1명이 모든 것 담당)
- 기술 부채 증가 (커스텀 스크립트 유지보수 어려움)

운영 영향:
- 장애 대응 시간: 2-4시간 (수동 재처리)
- 데이터 품질 문제: 중간 (일부 에러 처리 미흡)
- 확장성: 한계 (500GB 처리 불가능)
```

### 성공 기준

```
현재: 배치 처리 (일 2회, 2-4시간)
목표: 실시간 처리 (< 5분 지연)
기간: 3개월 (마이그레이션 + 검증)

측정 가능한 지표:
1. 데이터 지연: 2-4시간 → < 5분
2. 확장성: 100GB → 500GB 처리 가능
3. 운영 복잡도: 높음 → 중간 (90% 자동화)
4. 인프라 비용: $2,000/월 → $3,500/월 (성장 고려)
5. 팀 생산성: 운영 50% 시간 감소
```

### 스테이크홀더

```
영향받는 사람:
- Data Engineer: 일일 운영 부담, 기술 선택에 따른 학습곡선
- Data Scientist: 데이터 가용성 및 신선도
- CEO/CFO: 비용, 확장 가능성
- 고객: 분석 결과 품질 및 신선도

결정권자:
- CTO: 기술 선택 최종 결정
- Data Engineer: 운영 가능성 평가

실행자:
- Data Engineer: 마이그레이션 구현
- DevOps (신규): 인프라 관리
```

---

## Phase 2: 사고법 선택 및 적용

### 사고법 선택 이유

```
문제 유형: 기술 선택 + 아키텍처 설계
선택한 사고법: First Principles + Kepner-Tregoe
선택 이유:
- First Principles: 근본 요구사항부터 시작 (선택지 구성)
- Kepner-Tregoe: 체계적 의사결정 (선택지 평가)
- 기술 선택은 근본 문제 파악과 체계적 평가 필수
```

### First Principles 분석: 근본 요구사항 도출

#### 1단계: 근본 목표 정의

```
"데이터를 더 빨리 분석해야 한다"
↓
근본 질문들:
- 얼마나 빨리 필요한가? (5분? 1시간?)
- 어떤 유형의 분석? (통계? 머신러닝?)
- 얼마나 자주 변경? (정적? 동적?)
- 비용 제약이 있는가?
- 팀의 역량은? (학습곡선 고려)
```

#### 2단계: 근본 요구사항 분해

```
A. 처리 지연 요구사항
   상위 요구: "실시간 분석"
   근본 분해:
   - 고객의 실제 사용 사례: "1시간 이내 트렌드 파악" → 실제 필요는 < 1시간
   - 현재 배치: 2-4시간 → 충분하지 않음
   - 목표: < 5분 지연 (현실적 실시간)

B. 데이터 양 요구사항
   상위 요구: "월 500GB 처리"
   근본 분해:
   - 성장률: 월 400GB → 500GB (6개월)
   - 피크 시간대: 점심시간 10배 증가
   - 저장 기간: 2년 (1.2TB 누적)
   - 버전 관리: 이전 결과 보존 필요

C. 운영 요구사항
   상위 요구: "지속 가능한 시스템"
   근본 분해:
   - 팀 규모: 현재 1명 (전문가 부족)
   - 학습 시간: 새 기술 학습에 4주 소요 가능
   - 장애 대응: 자동 복구 필요 (수동 대응 불가)
   - 모니터링: 기본 알림만 필요 (상세 분석 추후)

D. 비용 요구사항
   상위 요구: "합리적 인프라 비용"
   근본 분해:
   - 현재: $2,000/월 (500GB: $4,000-6,000 추정)
   - 목표: $3,500/월 (성장 흡수)
   - 운영 비용: 추가 엔지니어 필요? (기술 선택에 따라)

E. 기술 부채 요구사항
   상위 요구: "유지보수 용이한 시스템"
   근본 분해:
   - 커스텀 코드: 최소화 (관리형 서비스 선호)
   - 사용자 커뮤니티: 크고 활발해야 함
   - 문서화: 충분해야 함
```

### Kepner-Tregoe 의사결정: 후보 기술 평가

#### 1단계: 후보 기술 선정

```
현재 고려 중인 옵션들:

1. Apache Kafka + Apache Spark Streaming + AWS RDS
   - 스트리밍 데이터 파이프라인
   - 오픈소스, 커뮤니티 크고 활발

2. AWS Kinesis + Lambda + DynamoDB
   - AWS 관리형 서비스
   - 운영 간단, 자동 확장

3. Google Cloud Dataflow (Apache Beam)
   - Google 관리형 서비스
   - 배치/스트림 통합 가능

4. Airflow + Spark + S3 (현재의 진화)
   - 현재 환경 기반 점진적 개선
   - 커스텀 스크립트 정리
```

#### 2단계: 평가 기준 정의 및 가중치

```
평가 기준 (중요도 순):

1. 지연 성능 (25%)
   - 5분 이내 처리 가능한가?
   - 피크 시간 처리 가능한가?

2. 확장성 (20%)
   - 500GB/월 처리 가능한가?
   - 1TB/월까지 확장 가능한가?

3. 운영 복잡도 (20%)
   - 1명 엔지니어 관리 가능한가?
   - 자동 장애 복구 가능한가?

4. 비용 (15%)
   - $3,500/월 이내 가능한가?
   - 비용 예측 가능한가?

5. 학습곡선 (10%)
   - 기존 팀이 배우기 쉬운가?
   - 커뮤니티 리소스가 풍부한가?

6. 장기 지속성 (10%)
   - 기술이 계속 주류인가?
   - 의존성이 높지 않은가?
```

#### 3단계: 각 후보 평가

```
옵션 1: Kafka + Spark Streaming + RDS

지연 성능: 8/10
- 스트리밍 처리 가능 (sub-second 가능)
- 파이프라인 복잡도 높으면 지연 증가 가능

확장성: 9/10
- Kafka: 대규모 데이터 처리 설계
- Spark: 수평 확장 용이
- 1TB/월까지 확장 가능

운영 복잡도: 4/10
- 여러 컴포넌트 조합 (Kafka, Zookeeper, Spark)
- 모니터링, 튜닝 복잡함
- 1명 엔지니어로 관리 어려움

비용: 6/10
- Kafka/Spark: 오픈소스 (비용 0)
- 서버 비용: $3,500-5,000/월
- 학습곡선 가파름 → 초기 컨설팅 필요

학습곡선: 3/10
- 매우 가파름 (6-8주 학습 필요)
- 팀 전문성 필요
- 커뮤니티는 크지만 초보자 가이드 적음

장기 지속성: 9/10
- Kafka: 업계 표준 (LinkedIn, Netflix, Uber 사용)
- 지속적 개선 및 업데이트
- 큰 생태계

종합 점수: (8×0.25) + (9×0.20) + (4×0.20) + (6×0.15) + (3×0.10) + (9×0.10)
         = 2.0 + 1.8 + 0.8 + 0.9 + 0.3 + 0.9 = 6.7/10
```

```
옵션 2: AWS Kinesis + Lambda + DynamoDB

지연 성능: 9/10
- 완전 관리형 (자동 확장)
- 마이크로초 단위 지연
- 실시간 처리 설계됨

확장성: 10/10
- AWS 자동 확장
- Kinesis Shard 자동 분할
- 무제한 확장 (비용만 고려)

운영 복잡도: 9/10
- 관리형 서비스 (AWS가 관리)
- 모니터링: CloudWatch 기본 제공
- 1명 엔지니어도 충분

비용: 7/10
- Kinesis: 처리량 기반 비용 ($0.27/시간)
- Lambda: 요청 기반 ($0.20/백만)
- DynamoDB: 필요에 따라 선택
- 추정: $2,500-3,500/월

학습곡선: 8/10
- AWS 기본 이해 필요
- Lambda/Kinesis 문서 충분
- 온보딩 2-3주 정도

장기 지속성: 9/10
- AWS: 지속적인 서비스 개선
- 업계 표준이 아니나 AWS 생태계 중심
- 의존성: AWS 종속성 높음

종합 점수: (9×0.25) + (10×0.20) + (9×0.20) + (7×0.15) + (8×0.10) + (9×0.10)
         = 2.25 + 2.0 + 1.8 + 1.05 + 0.8 + 0.9 = 8.8/10
```

```
옵션 3: Google Cloud Dataflow

지연 성능: 8/10
- Beam 기반 (배치/스트림 통합)
- 자동 최적화
- 지연: < 1분 일반적

확장성: 10/10
- Google Cloud 자동 확장
- 수평/수직 확장 자동
- 무제한 용량

운영 복잡도: 8/10
- Google이 인프라 관리
- Dataflow 모니터링 기본 제공
- 1명 엔지니어 가능

비용: 6/10
- 처리 리소스: $0.25/시간
- 저장소: GCS $0.02/GB
- 추정: $3,000-4,000/월
- AWS보다 약간 비쌈

학습곡선: 6/10
- Beam 개념 이해 필요
- Dataflow 학습곡선 중간
- 문서: 적당함

장기 지속성: 7/10
- Google Cloud가 지속 개발
- Beam: 오픈소스로 생태계 있음
- 하지만 AWS/Azure보다 시장 점유율 낮음

종합 점수: (8×0.25) + (10×0.20) + (8×0.20) + (6×0.15) + (6×0.10) + (7×0.10)
         = 2.0 + 2.0 + 1.6 + 0.9 + 0.6 + 0.7 = 7.8/10
```

```
옵션 4: Airflow + Spark + S3 (점진적 개선)

지연 성능: 5/10
- Airflow는 배치 처리 (스트림 미지원)
- Spark로 개선하면 5-10분 가능
- 현재보다 개선 필요

확장성: 7/10
- Spark 수평 확장 가능
- Airflow DAG 복잡도 증가
- 500GB는 가능, 이상 어려움

운영 복잡도: 5/10
- Airflow 모니터링/튜닝 필요
- 커스텀 오퍼레이터 작성 가능
- 중간 정도 복잡도

비용: 8/10
- 오픈소스 (비용 0)
- 서버 비용: $2,000-3,000/월
- 비용 효율적

학습곡선: 7/10
- Airflow: 현재 팀이 부분 학습함
- Spark: 추가 학습 필요 (2-3주)
- 온보딩: 3-4주

장기 지속성: 8/10
- Airflow: Airbnb 오픈소스, 활발한 커뮤니티
- Spark: 업계 표준
- 문제: 스트림 처리가 미래 필요이면 부족

종합 점수: (5×0.25) + (7×0.20) + (5×0.20) + (8×0.15) + (7×0.10) + (8×0.10)
         = 1.25 + 1.4 + 1.0 + 1.2 + 0.7 + 0.8 = 6.35/10
```

#### 4단계: 최종 순위

```
1. AWS Kinesis + Lambda + DynamoDB: 8.8/10 ← 추천
2. Google Cloud Dataflow: 7.8/10
3. Kafka + Spark Streaming: 6.7/10
4. Airflow + Spark + S3: 6.35/10

권장사항:
AWS Kinesis (옵션 2) 선택
이유:
✅ 운영 복잡도 최저 (1명 엔지니어 가능)
✅ 지연 성능 최고 (실시간 요구 충족)
✅ 학습곡선 합리적 (3주 내 운영 가능)
✅ 비용 예측 가능 (상층 제한 필요)
✅ 장기 생태계 우수 (AWS 중심)

위험:
⚠️ AWS 종속성 (이후 마이그레이션 어려움)
⚠️ 비용: 성장에 따라 빠르게 증가 가능
⚠️ 팀이 AWS 깊이 있어야 함
```

---

## Phase 3: 연구 계획

### 연구 필요성 판단

```
의사결정 신뢰도: 70% (평가 기준은 명확하지만 실제 구현 불확실)
확인해야 할 것:
1. AWS Kinesis 실제 운영 난이도 (평가: 9 맞는가?)
2. 비용 추정 정확도 (실제로 $3,500 맞는가?)
3. 마이그레이션 시간 추정 (3개월 현실적?)
4. 기존 데이터 마이그레이션 전략 (손실 최소화)
```

### 연구 계획

```
Priority 1 (필수):
1. "AWS Kinesis 실제 운영 사례" → Tier 2
   - 비슷한 규모의 회사 사례
   - 실제 운영 어려움, 장점

2. "Kinesis 비용 계산기 + 실제 비용" → Tier 1
   - AWS 공식 비용 계산
   - 실제 청구 사례

3. "마이그레이션 전략" → Tier 2
   - Lambda 배포 프로세스
   - 이중 처리 기간 (점진적 전환)

Priority 2 (권장):
4. "Kinesis vs Kafka 실제 비교" → Tier 2
   - 운영 복잡도 비교
   - 처리량 비교

5. "AWS Lambda 콜드 스타트" → Tier 2
   - 지연 성능 실제 영향
```

---

## Phase 4: 연구 실행 및 기록

### 연구 1: AWS Kinesis 실제 운영 사례

```
질문: 비슷한 규모 (100GB-500GB) 회사들의 Kinesis 운영 경험?
출처: AWS Case Studies, Reddit r/aws, 기술 블로그
출처 신뢰도: Tier 2-3

찾은 정보:
✅ 운영 복잡도 실제 평가:
   - 설정 후 대부분 자동 (맞음)
   - 모니터링: CloudWatch 알림만으로 충분
   - 장애 대응: 거의 없음 (AWS가 관리)
   - 실제 소요 시간: 주당 2-3시간 정도

✅ 실제 문제 포인트:
   - Partition Key 설계 중요 (데이터 분산)
   - Lambda 콜드 스타트 (초기 지연 수초)
   - DynamoDB 용량 계획 필요

✅ 비용 관리:
   - 예상 외 비용 사례: 거의 없음 (설계 따로)
   - 비용 최적화: Shard 자동 확장 사용 권장

신뢰도 평가: 75%
(실제 운영자들의 증언, 하지만 조건 다를 수 있음)
```

### 연구 2: AWS 비용 계산

```
질문: 월 500GB 데이터 처리 시 실제 비용?
출처: AWS Pricing Calculator + 실제 청구 사례
출처 신뢰도: Tier 1

찾은 정보:
✅ Kinesis 비용:
   - Shards: 500GB/월 = 약 20 shards 필요
   - Shard 시간당 비용: $0.27
   - 월간 (730시간): 20 × $0.27 × 730 = $3,942

✅ Lambda 비용:
   - 호출: 500GB ÷ 1MB = 5억 번
   - 비용: 5억 × $0.0000002 = $100
   - 지연: 100ms × 5억 = 5천만초 (약 1,600시간)
   - 컴퓨트: 1,600 × $0.0000166 = $27

✅ DynamoDB 비용:
   - 저장: 500GB × $1.25 = $625
   - 읽기: 500GB ÷ 4KB = 1억 개
   - 1억 × $0.00000125 = $125

✅ 기타 (S3, CloudWatch 등):
   - 예상: $300-500

✅ 총 예상 비용: $5,000-5,500/월

신뢰도 평가: 85%
(공식 계산기 기반, 실제 변동 가능성 있음)
```

### 연구 3: 마이그레이션 전략

```
질문: RDS + Lambda에서 Kinesis + Lambda로 안전하게 전환?
출처: AWS 마이그레이션 가이드 + 사례 연구
출처 신뢰도: Tier 2

찾은 정보:
✅ 마이그레이션 단계:
   Week 1-2: Kinesis 설정 + Lambda 개발
   Week 3-4: 테스트 (카나리)
   Week 5-6: 이중 처리 (기존 + 신규 동시)
   Week 7-8: 신규 우선, 이전 롤백 대기
   Week 9: 기존 시스템 폐지

✅ 이중 처리 전략:
   - 기존: RDS 계속 처리
   - 신규: Kinesis/Lambda 동시 처리
   - 검증: 두 결과 비교 (불일치 감지)
   - 기간: 2주 (충분한 데이터 커버)

✅ 데이터 손실 방지:
   - Kinesis Retention: 24시간 (기본)
   - Dead Letter Queue: 실패 건 재처리
   - 모니터링: 모든 에러 알림

신뢰도 평가: 80%
(검증된 접근법, 하지만 우리 스택에 맞춰야 함)
```

### 연구 종합

```
주요 발견 1:
AWS Kinesis는 운영적으로 간단함 (주당 2-3시간)
출처: 실제 운영자 증언 (Tier 2)
신뢰도: 75%
우리 맥락: 1명 엔지니어로 관리 가능 (평가 맞음)

주요 발견 2:
비용이 예상 $3,500보다 높음 ($5,000-5,500)
출처: 공식 계산기 (Tier 1)
신뢰도: 85%
우리 맥락: 비용 재검토 필요 (사업 영향도 검토)

주요 발견 3:
마이그레이션에 8-9주 소요 (목표 3개월 달성 가능)
출처: 마이그레이션 가이드 (Tier 2)
신뢰도: 80%
우리 맥락: 일정은 타이트하지만 가능

주요 발견 4:
이중 처리 검증 기간이 중요 (데이터 정합성)
출처: 마이그레이션 모범사례 (Tier 2)
신뢰도: 80%
우리 맥락: 2주 검증 기간 필수
```

---

## Phase 5: 통합 분석 및 신뢰도 재계산

### Kepner-Tregoe 평가 + 연구 증거 통합

```
초기 Kepner-Tregoe 평가:
AWS Kinesis: 8.8/10 (최고)
근거: 운영 간단, 지연 낮음, 학습 용이

연구 결과:
- 운영 복잡도: 평가 맞음 (주당 2-3시간)
- 비용: 예상보다 높음 ($3,500 → $5,000)
- 마이그레이션: 일정 타이트하지만 가능
- 검증 기간: 추가 2주 필요

통합 결론:
✅ AWS Kinesis 선택은 여전히 최적
🔴 비용 증가 → 사업 승인 확인 필요
⚠️ 일정: 3개월은 타이트 (4개월 더 안전)

조정:
- 목표: 3개월 → 4개월 (마진 확보)
- 비용: $3,500 → $5,200/월 (승인 필요)
```

### 신뢰도 최종 계산

```
방법 신뢰도: 80%
  사용한 방법: First Principles + Kepner-Tregoe
  근거: 체계적 평가 기준 (6개 항목), 정량적 점수
  감점: Kepner-Tregoe 점수가 예측일 뿐 (-10%)
        First Principles 분석에 가정 포함 (-10%)

증거 신뢰도: 80%
  사용한 출처들:
  - Tier 1: 1개 (AWS 비용 계산기) → 신뢰도 90%
  - Tier 2: 3개 (운영 사례, 마이그레이션, 비교) → 신뢰도 75%

  평균 = (1×0.9 + 3×0.75) / 4 = 3.15 / 4 = 0.79 → 79%

상황 적합도: 75%
  시간: 3개월 목표, 4개월 추천 (동의 필요)
  리소스: 1명 엔지니어 + DevOps (신규 필요)
  기술 선택 적합도: 높음 (요구사항 충족)
  감점: 비용 증가로 승인 불확실 (-15%)
        팀 확보 불확실 (-10%)

최종 신뢰도 점수: 80% × 80% × 75% = 48%

→ 중-저 수준의 신뢰도 (조건부 실행 권장)
```

### 신뢰도 해석

```
신뢰도 48%의 의미:
✅ 우리 선택이 맞을 확률: 48%
❌ 우리 선택이 틀릴 확률: 52%

의사결정 추천:
[ ✓ ] 조건부 승인 + PoC (Proof of Concept)
  1. 비용 증가 ($5,200/월) 사업 승인 필요
  2. DevOps 엔지니어 채용 또는 계약 필요
  3. PoC 구현 (1개 파이프라인): 2주
  4. PoC 검증 후 본격 마이그레이션 결정

위험 요소:
1. 비용이 예상보다 높음 → 사업 거부 가능성
2. 비용 관리 미흡 → 월 $10K 이상 증가 가능
3. 팀 부재 → 구현 어려움
4. 성능 미달 → Lambda 콜드 스타트 영향

위험 완화 방법:
1. CFO와 비용 사전 협의 (상한선 설정)
2. 비용 모니터링 (CloudWatch 알림)
3. DevOps 즉시 채용 추진
4. Lambda 워밍 전략 (비용 증가) vs 성능 트레이드오프
```

---

## Phase 6: 의사결정 및 액션 플랜

### 최종 의사결정

```
결정:
"AWS Kinesis + Lambda + DynamoDB 선택,
다음 조건에서 구현 진행:
1. 월 비용 상한선: $5,500 (CFO 승인)
2. DevOps 엔지니어 채용 또는 계약 확보
3. PoC 성공 후 본격 마이그레이션 진행"

근거:
1. First Principles 분석으로 근본 요구사항 명확 (신뢰도 80%)
2. Kepner-Tregoe로 체계적 평가 (8가지 기준)
3. 3개 기술 비교에서 최고 점수 (8.8/10)
4. 연구로 운영 복잡도 검증 (신뢰도 75%)
5. 마이그레이션 경로 검증 (신뢰도 80%)

위험 요소:
1. 비용 증가 ($3,500 → $5,200): CFO 거부 가능
2. 팀 부재: 구현 지연 가능
3. 성능 예상 미달: Lambda 콜드 스타트 (+수초)

위험 완화 방법:
1. 비용 모니터링 및 최적화 (Shard 자동 조정)
2. DevOps 신규 채용 (즉시 시작)
3. PoC로 실제 성능 검증 (Lambda 워밍 전략 적용)
```

### 액션 플랜

#### 즉시 실행 (0-1주) - 승인 및 준비

```
액션 1: CFO 비용 승인 획득
- 목표: 월 $5,200 비용 상한선 승인
- 소유자: 기술 리드 + CFO
- 타임라인: 3-5일
- 리소스: 비용 제안서, 사업 임팩트 분석
- 성공 기준: 서면 승인 획득

액션 2: DevOps 엔지니어 채용 계획
- 목표: 3주 내 외부 계약 DevOps 확보
- 소유자: HR
- 타임라인: 즉시 시작
- 리소스: 채용 공고, 계약사 연락
- 성공 기준: 계약 확정

액션 3: 기술 검토 팀 구성
- 참여자: Data Engineer, DevOps, CTO
- 목표: 마이그레이션 계획 상세 수립
- 산출물: 상세 마이그레이션 일정 (주 단위)
- 성공 기준: 팀 합의한 계획 완성

액션 4: AWS 계정 및 기본 구성
- 할 일: Kinesis/Lambda/DynamoDB 프로덕션 계정 생성
- 소유자: DevOps
- 리소스: AWS 액세스 관리
- 성공 기준: 계정 생성 및 VPC 기본 설정
```

#### 단기 실행 (1-3주) - PoC 구현

```
액션 1: 1개 파이프라인 PoC 구현
- 목표: 가장 간단한 데이터 파이프라인 1개 마이그레이션
- 예상 시간: 2주
- 소유자: Data Engineer + DevOps
- 범위:
  - Kinesis Stream 생성
  - Lambda 함수 개발 (기존 로직 포팅)
  - DynamoDB 테이블 생성
  - CloudWatch 모니터링 설정

세부 단계:
  1. 기존 파이프라인 분석 (1일)
  2. Kinesis Stream 설계 (2일)
  3. Lambda 함수 포팅 (5일)
  4. DynamoDB 스키마 설계 (1일)
  5. 로컬 테스트 (2일)
  6. Staging 배포 (1일)

성공 기준:
  - Kinesis → Lambda → DynamoDB 흐름 작동
  - 성능: < 5분 지연 달성
  - 에러율: < 0.1%
  - 비용: $50-100/일 (예상 범위)

액션 2: 성능 테스트 및 비용 검증
- 목표: 실제 비용 및 성능 측정
- 타임라인: 1주 (PoC 운영)
- 측정 항목:
  - 실제 비용 (CloudWatch)
  - 지연 시간 (P50, P95, P99)
  - Lambda 콜드 스타트 빈도
  - 에러율 및 재시도

성공 기준:
  - 비용: $50-100/일 범위 내
  - 지연: < 5분 (목표)
  - Lambda 콜드 스타트: < 5초 (수용 가능)
  - 에러율: < 0.1% (목표)

액션 3: PoC 검증 및 Go/No-Go 결정
- 목표: 본격 마이그레이션 진행 여부 최종 결정
- 주최자: CTO + 기술 리드
- 평가 기준:
  - 성능 목표 달성 여부
  - 비용이 예측 범위 내인가
  - 팀이 운영 가능한가
  - 위험 요소는 제어 가능한가

Go 조건:
  - ✅ 지연 < 5분 달성
  - ✅ 비용 예측 정확 (±20%)
  - ✅ 팀이 운영 확신
  - ✅ 일정 여유 있음

No-Go 조건:
  - ❌ 성능 목표 미달
  - ❌ 비용 예상 초과 (> $150/일)
  - ❌ Lambda 콜드 스타트 > 30초
```

#### 중기 실행 (3-10주) - 본격 마이그레이션

```
액션 1: 모든 파이프라인 마이그레이션
- 목표: 기존 모든 파이프라인을 Kinesis 기반으로 변환
- 예상 시간: 6주
- 소유자: Data Engineer + DevOps (2명)
- 단계별 마이그레이션:
  Week 1-2: 파이프라인 1-5 마이그레이션
  Week 3-4: 파이프라인 6-10 마이그레이션
  Week 5-6: 파이프라인 11-15 마이그레이션 (나머지)

각 파이프라인:
  - 설계 검토 (0.5일)
  - 구현 (2-5일, 복잡도에 따라)
  - 테스트 (1-2일)
  - Staging 배포 (0.5일)

성공 기준:
  - 모든 파이프라인 Kinesis 마이그레이션 완료
  - 성능 목표 달성 (< 5분 지연)
  - 에러율 < 0.1% 유지

액션 2: 이중 처리 검증 (기존 + 신규)
- 목표: 데이터 정합성 검증
- 기간: 2주 (모든 마이그레이션 완료 후)
- 과정:
  - 기존 RDS Lambda 계속 실행
  - 신규 Kinesis Lambda 동시 실행
  - 결과 비교 (매일)
  - 불일치 분석 및 수정

성공 기준:
  - 데이터 불일치 0건 달성
  - 또는 불일치의 원인 파악 및 수정

액션 3: 기존 시스템 폐기
- 목표: RDS Lambda 시스템 중단
- 타임라인: 검증 완료 후 1주
- 과정:
  - RDS 읽기 전용 전환
  - 기존 Scheduler 중단
  - 아카이빙 및 백업
  - 비용 모니터링 (RDS → Kinesis 비용 비교)

성공 기준:
  - RDS 중단 (비용 $500/월 감소 기대)
  - 아카이빙 완료
  - 최종 비용: 예상 $5,200 범위 내
```

#### 장기 실행 (10-12주) - 최적화 및 안정화

```
액션 1: 비용 최적화
- 목표: 운영 비용을 $4,500/월 이하로 감소
- 소유자: DevOps
- 최적화 방법:
  - Kinesis Shard 자동 스케일링 (불필요 Shard 제거)
  - DynamoDB on-demand vs 예약 용량 평가
  - Lambda 메모리 최적화 (비용 vs 시간)
  - 데이터 보존 정책 최적화 (1년 이상 오래된 것 아카이빙)

성공 기준:
  - 월 비용: $4,500-5,000 달성
  - 성능 유지 (지연 < 5분)

액션 2: 모니터링 및 알림 강화
- 목표: 운영 자동화 및 문제 조기 감지
- 구성:
  - CloudWatch 대시보드 (실시간 모니터링)
  - 자동 알림 (에러율, 지연, 비용)
  - 주간 리뷰 미팅 (성능 분석)

성공 기준:
  - 모니터링 자동화 100% 구축
  - 평균 장애 대응 시간: < 15분

액션 3: 팀 교육 및 문서화
- 목표: 1명 엔지니어만으로도 독립 운영 가능
- 범위:
  - Kinesis 아키텍처 교육 (4시간)
  - Lambda 디버깅 교육 (4시간)
  - DynamoDB 성능 튜닝 교육 (2시간)
  - 운영 매뉴얼 작성 (장애 대응, 비용 관리)

성공 기준:
  - 1명 엔지니어가 독립 운영 가능
  - 모든 문서 작성 및 검토 완료
  - 비상 연락처 체계 구축
```

---

## Phase 7: 실행 후 학습

### 예상 vs 실제 (4개월 후)

```
예상했던 결과:
- 지연: 2-4시간 → < 5분 (목표)
- 확장성: 100GB → 500GB 처리 가능
- 운영: 주당 50시간 → 주당 10시간
- 비용: $2,000/월 → $5,200/월

실제 결과 (4개월 후):
[구현이 완료되면 기록]
- 실제 달성 지연 시간
- 확장 가능성
- 운영 시간
- 실제 발생 비용

비교 분석:
- 성능 목표 달성 여부
- 비용 증가의 사업 임팩트
- 팀 운영 난이도
- 미예상 문제점
```

### 신뢰도 재평가

```
초기 신뢰도: 48%
최종 실제 신뢰도: [구현 후 평가]

검증 사항:
- First Principles 분석의 정확도
- Kepner-Tregoe 점수 vs 실제 성능
- 연구 정보의 신뢰도 (특히 비용)
- 기술 선택의 타당성

학습 적용:
- 다음 기술 선택에 사용할 원칙
- 비용 예측 방법 개선
- 위험 관리 프로세스
```

---

## 📊 빠른 참조

| 구분 | 내용 |
|------|------|
| **사고법** | First Principles + Kepner-Tregoe |
| **선택 기술** | AWS Kinesis + Lambda + DynamoDB |
| **점수** | 8.8/10 (3개 대안 중 1위) |
| **신뢰도** | 48% → 조건부 승인 + PoC 권장 |
| **일정** | 4개월 (PoC 2주 + 마이그레이션 6주 + 최적화 2주) |
| **비용** | $5,200/월 (예상) |
| **위험** | 비용 초과, 팀 부재, 성능 미달 |
| **다음 단계** | CFO 승인 + DevOps 채용 + PoC 구현 |

---

**Version**: 1.0.0
**Last Updated**: 2025-11-07
**적용 사례**: 스타트업 데이터 파이프라인 아키텍처 선택 (기술적 의사결정)
